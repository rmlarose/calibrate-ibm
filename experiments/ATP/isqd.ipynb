{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQD postprocessing for ATP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment = \"atp_0_be2_f4\"\n",
    "\n",
    "all_adapt_iterations = [1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcParams.update({\"font.family\": \"serif\"})\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import pyscf.tools\n",
    "from pyscf import ao2mo\n",
    "\n",
    "import collections\n",
    "from functools import partial\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from qiskit.primitives import BitArray\n",
    "from qiskit_addon_sqd.fermion import SCIResult, diagonalize_fermionic_hamiltonian, solve_sci_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_bitstring(bits):\n",
    "    \"\"\"\n",
    "    Convert a given bitstring from Openfermion convention \n",
    "    (alternating alpha/beta, big endian) to Qiskit (all alpha\n",
    "    then all beta, little endian).\n",
    "    \"\"\"\n",
    "\n",
    "    left = [bits[i] for i in range(len(bits)) if i % 2 == 1]   # beta\n",
    "    right = [bits[i] for i in range(len(bits)) if i % 2 == 0]  # alpha\n",
    "\n",
    "    # Reverse each half\n",
    "    left.reverse()\n",
    "    right.reverse()\n",
    "\n",
    "    # Concatenate\n",
    "    return ''.join(left + right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import qiskit.visualization\n",
    "\n",
    "\n",
    "# qiskit.visualization.plot_histogram(\n",
    "#     all_counts_hardware[0],\n",
    "#     # target_string=hartree_fock_bitstring,\n",
    "#     # sort=\"hamming\",\n",
    "#     number_to_keep=10,\n",
    "#     figsize=(7, 8),\n",
    "#     title=computer.name,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_dir = \"circuits\"\n",
    "hamiltonian_dir = \"hamiltonians\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing hamiltonians/atp_0_be2_f4.fcidump\n"
     ]
    }
   ],
   "source": [
    "fcidump = pyscf.tools.fcidump.read(f\"{hamiltonian_dir}/{fragment}.fcidump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_orbitals = fcidump.get(\"NORB\")\n",
    "num_electrons = fcidump.get(\"NELEC\")\n",
    "ecore = fcidump.get(\"ECORE\")\n",
    "h1 = fcidump.get(\"H1\")\n",
    "h2 = fcidump.get(\"H2\")\n",
    "h2 = ao2mo.restore(1, h2, n_orbitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nqubits = 2 * n_orbitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADAPT iteration 1\n",
      "Most common bitstring: 0000000000000000111111111111111100000000000000001111111111111111 with count 41125\n",
      "Total number of bitstrings: 1926\n",
      "Total number of samples: 100000\n",
      "ADAPT iteration 2\n",
      "Most common bitstring: 0000000000000000111111111111111100000000000000001111111111111111 with count 37918\n",
      "Total number of bitstrings: 2613\n",
      "Total number of samples: 100000\n"
     ]
    }
   ],
   "source": [
    "all_counts = []\n",
    "fnames = []\n",
    "\n",
    "for adapt_iterations in all_adapt_iterations:\n",
    "    fname = glob.glob(f\"{results_dir}/{fragment}/*{adapt_iterations:03d}*.qasm*\")[0]\n",
    "    counts = pickle.load(\n",
    "        open(f\"{fname}\", \"rb\")\n",
    "    )\n",
    "    mode_order = pickle.load(\n",
    "        open(f\"{circuit_dir}/{fragment}/{fragment}_mode_order_{adapt_iterations:03d}_adaptiterations.pkl\", \"rb\")\n",
    "    )\n",
    "    qubit_order = pickle.load(\n",
    "        open(f\"{circuit_dir}/{fragment}/{fragment}_qubit_order_{adapt_iterations:03d}_adaptiterations.pkl\", \"rb\")\n",
    "    )\n",
    "\n",
    "    measurement_outcomes = counts\n",
    "    permuted_outcomes = {}\n",
    "    for original_bitstring in measurement_outcomes.keys():\n",
    "        qubit_permuted_bitstring = \"\".join([original_bitstring[qubit_order.index(n)] for n in range(nqubits)])\n",
    "        mode_permuted_bitstring = \"\".join([qubit_permuted_bitstring[mode_order.index(n)] for n in range(nqubits)])\n",
    "\n",
    "        final_permuted_bitstring = transform_bitstring(mode_permuted_bitstring)\n",
    "        permuted_outcomes[final_permuted_bitstring[::]] = measurement_outcomes[original_bitstring]\n",
    "    \n",
    "    counts = permuted_outcomes\n",
    "    all_counts.append(counts)\n",
    "\n",
    "    print(\"ADAPT iteration\", adapt_iterations)\n",
    "    max_key = max(counts, key=counts.get)\n",
    "    print(f'Most common bitstring: {max_key} with count {counts[max_key]}')\n",
    "    print(f'Total number of bitstrings: {len(counts)}')\n",
    "    print(f\"Total number of samples:\", sum(counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement strategies to cap the number of shots when concatenating.\n",
    "counts = collections.Counter()\n",
    "for c in all_counts:\n",
    "    for bitstring, count in c.items():\n",
    "        counts[bitstring] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_array = BitArray.from_counts(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "\tSubsample 0\n",
      "\t\tEnergy: -261.8116206022048\n",
      "\t\tSubspace dimension: 38416\n",
      "\tSubsample 1\n",
      "\t\tEnergy: -261.8116206022048\n",
      "\t\tSubspace dimension: 38416\n",
      "Iteration 2\n",
      "\tSubsample 0\n",
      "\t\tEnergy: -261.8468641903113\n",
      "\t\tSubspace dimension: 69169\n",
      "\tSubsample 1\n",
      "\t\tEnergy: -261.8468641903113\n",
      "\t\tSubspace dimension: 69169\n",
      "Iteration 3\n",
      "\tSubsample 0\n",
      "\t\tEnergy: -261.85616403303584\n",
      "\t\tSubspace dimension: 74529\n",
      "\tSubsample 1\n",
      "\t\tEnergy: -261.85616403303584\n",
      "\t\tSubspace dimension: 74529\n",
      "Iteration 4\n",
      "\tSubsample 0\n",
      "\t\tEnergy: -261.86130074139237\n",
      "\t\tSubspace dimension: 75625\n",
      "\tSubsample 1\n",
      "\t\tEnergy: -261.86130074139237\n",
      "\t\tSubspace dimension: 75625\n",
      "Iteration 5\n",
      "\tSubsample 0\n",
      "\t\tEnergy: -261.8613067564842\n",
      "\t\tSubspace dimension: 76729\n",
      "\tSubsample 1\n",
      "\t\tEnergy: -261.8613067564842\n",
      "\t\tSubspace dimension: 76729\n",
      "Iteration 6\n",
      "\tSubsample 0\n",
      "\t\tEnergy: -261.86132526803834\n",
      "\t\tSubspace dimension: 78400\n",
      "\tSubsample 1\n",
      "\t\tEnergy: -261.86132526803834\n",
      "\t\tSubspace dimension: 78400\n",
      "Iteration 7\n",
      "\tSubsample 0\n",
      "\t\tEnergy: -261.8613304933385\n",
      "\t\tSubspace dimension: 80089\n",
      "\tSubsample 1\n",
      "\t\tEnergy: -261.8613304933385\n",
      "\t\tSubspace dimension: 80089\n",
      "Iteration 8\n",
      "\tSubsample 0\n",
      "\t\tEnergy: -261.8613304933385\n",
      "\t\tSubspace dimension: 80089\n",
      "\tSubsample 1\n",
      "\t\tEnergy: -261.8613304933385\n",
      "\t\tSubspace dimension: 80089\n"
     ]
    }
   ],
   "source": [
    "energy_tol = 1e-8\n",
    "occupancies_tol = 1e-8\n",
    "carryover_threshold = 1e-5\n",
    "\n",
    "sci_solver = partial(solve_sci_batch, spin_sq=0, max_cycle=10000)\n",
    "result_history = []\n",
    "\n",
    "def callback(results: list[SCIResult]):\n",
    "    result_history.append(results)\n",
    "    iteration = len(result_history)\n",
    "    print(f\"Iteration {iteration}\")\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"\\tSubsample {i}\")\n",
    "        print(f\"\\t\\tEnergy: {result.energy + ecore}\")\n",
    "        print(f\"\\t\\tSubspace dimension: {np.prod(result.sci_state.amplitudes.shape)}\")\n",
    "\n",
    "\n",
    "result = diagonalize_fermionic_hamiltonian(\n",
    "    one_body_tensor=h1,\n",
    "    two_body_tensor=h2,\n",
    "    bit_array=bit_array,\n",
    "    samples_per_batch=500,\n",
    "    norb=n_orbitals,\n",
    "    nelec=(num_electrons // 2, num_electrons // 2),\n",
    "    num_batches=2,\n",
    "    energy_tol=energy_tol,\n",
    "    occupancies_tol=occupancies_tol,\n",
    "    max_iterations=100,\n",
    "    sci_solver=sci_solver,\n",
    "    symmetrize_spin=True,\n",
    "    carryover_threshold=carryover_threshold,\n",
    "    callback=callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(-261.8116206022048),\n",
       " np.float64(-261.8468641903113),\n",
       " np.float64(-261.85616403303584),\n",
       " np.float64(-261.86130074139237),\n",
       " np.float64(-261.8613067564842),\n",
       " np.float64(-261.86132526803834),\n",
       " np.float64(-261.8613304933385),\n",
       " np.float64(-261.8613304933385)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_e = [\n",
    "    min(result, key=lambda res: res.energy).energy + ecore\n",
    "    for result in result_history\n",
    "]\n",
    "min_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqd_energies_1_2_adaptiterations.txt'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations_key = \"_\".join(map(str, all_adapt_iterations))\n",
    "save_name = f\"sqd_energies_{iterations_key}_adaptiterations.txt\"\n",
    "save_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(save_name, min_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envq4bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
